{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs and Other Algorithms\n",
    "First few sections are on graph terminology, digraphs and undigraphs, weighted graphs, graph representations, adjacency lists, and adjacency matrices. Refer to the graphs on adjacency lists and adjacency matrices for the implementation of the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'B'), ('A', 'C'), ('B', 'E'), ('B', 'C'), ('B', 'A'), ('C', 'A'), ('C', 'B'), ('C', 'E'), ('C', 'F'), ('E', 'B'), ('E', 'C'), ('F', 'C')]\n"
     ]
    }
   ],
   "source": [
    "graph = dict()\n",
    "graph['A'] = ['B', 'C']\n",
    "graph['B'] = ['E', 'C', 'A']\n",
    "graph['C'] = ['A', 'B', 'E', 'F']\n",
    "graph['E'] = ['B', 'C']\n",
    "graph['F'] = ['C']\n",
    "\n",
    "# Create matrix dimensions\n",
    "matrix_elements = sorted(graph.keys())\n",
    "cols = rows = len(matrix_elements)\n",
    "\n",
    "# Create need an edges\n",
    "adjacency_matrix = [[0 for x in range(rows)] for y in range(cols)]  # Creates a 5 x 5 zero matrix\n",
    "edges_list = []\n",
    "\n",
    "for key in matrix_elements:\n",
    "    for neighbor in graph[key]:\n",
    "        edges_list.append((key, neighbor))\n",
    "        \n",
    "print(edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0]\n",
      "[1, 0, 1, 1, 0]\n",
      "[1, 1, 0, 1, 1]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for edge in edges_list:\n",
    "    index_of_first_vertex = matrix_elements.index(edge[0])\n",
    "    index_of_second_vertex = matrix_elements.index(edge[1])\n",
    "    adjacency_matrix[index_of_first_vertex][index_of_second_vertex] = 1\n",
    "    \n",
    "for row in range(len(adjacency_matrix)):\n",
    "    print(adjacency_matrix[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph traversals\n",
    "A graph traversal means to visit all the vertices of the graph, while keeping track of which nodes or vertices have already been visited and which ones have not. A graph traversal algorithm is efficient if it traverses all the nodes of the graph in the minimum possible time. A common strategy of graph traversal is to follow a path until a dead end is reached, then traverse back up until there is a point where we meet an alternative path. We can also iteratively move from one node to another in order to traverse the full graph, or part of it. Graph traversal algorithms are very important in answering many fundamental problems-they can be useful to determine how to reach from one vertex to another in a graph, and which path from the A to B vertices in the graph is better than other paths. We will work with **breadth-first search (BFS)** and **depth-first search (DFS)**.\n",
    "### Breadth-first traversal\n",
    "Breadth-first traversal algorithms work breadth-wise in the graph, A queue data structure is used to store the information of vertices that are to be visited in the graph. We begin with the starting node. Firstly, we visit that node, and then we look up all of its neighboring, or adjacent, vertices. We first visit these adjacent vertices one by one, while adding their neighbors to the list of vertices that are to be visited. We follow this process until  we have visited all the vertices of the graph, ensuring that no vertex is visited twice.\n",
    "\n",
    "We explore the BFS algorithm of a graph on page 211. Here is the adjacency list for the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dict()\n",
    "graph['A'] = ['B', 'G', 'D']\n",
    "graph['B'] = ['A', 'F', 'E']\n",
    "graph['C'] = ['F', 'H']\n",
    "graph['D'] = ['F', 'A']\n",
    "graph['E'] = ['B', 'G']\n",
    "graph['F'] = ['B', 'D', 'C']\n",
    "graph['G'] = ['A', 'E']\n",
    "graph['H'] = ['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To traverse this graph using the BFS algorithm, we will employ the use of a queue. The algorithm creates a list to store the vertices that have been visited as the traversal process proceeds. We shall start our traversal from the `A` node.\n",
    "\n",
    "The `A` node is queued and added to the list of visited nodes. Afterward, we use a `while` loop to effect traversal of the graph. In the `while` loop, the `A` node is dequeued. Its unvisited adjacent nodes, B, G, and D, are sorted in alphabetical order and queued up. The queue will now contain the B, D, and G nodes. These nodes are also added to the list of visited nodes. At this point, we start another iteration of the `while` loop, because the queue is not empty, which also means that we are not really done with the traversal.\n",
    "\n",
    "The B node is dequeued. Out of its adjacent nodes, A, F, and E, node A has already been visited. Therefore, we only queue the E and F nodes in alphabetical order. The E and F nodes are then added to the list of visited nodes. Our queue now holds the following nodes at this point-D, G, E, and F. The list of visited nodes contains A, B, D, G, and F.\n",
    "\n",
    "The D node is dequeued, but all of its adjacent nodes have been visited, so we simply dequeue it. The next node at the front of the queue is G. We dequeue the G node, but also find out that all of its adjacent nodes have been visited, because they are in the list of visited nodes. So, the G node is also dequeued. We dequeue the E node too, because its nodes have also been visited. The only node in the queue now is the F node.\n",
    "\n",
    "The F node is dequeued, and we realize that out of its adjacent nodes, B, D, and C, only C has not been visited. We then enqueue the C node and add it to the list of visited nodes. Then, the C node is dequeued. C has adjacent nodes of F and H, but F has already been visited, leaving the H node. The H node is enqueued and added to the list of visited nodes.\n",
    "\n",
    "Finally, the last iteration of the `while` loop will lead to the H node being dequeued. Its only adjacent node, C, has already been visited. Once the queue is completely empty, the loop breaks. Here is the code for the BFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def breadth_first_search(graph, root):\n",
    "    # Initializing the traversal algorithm\n",
    "    visited_vertices = list()\n",
    "    graph_queue = deque([root])\n",
    "    visited_vertices.append(root)\n",
    "    node = root\n",
    "    # While loop to execute the BFS algorithm\n",
    "    while len(graph_queue) > 0:\n",
    "        # Pop the node off the graph queue\n",
    "        node = graph_queue.popleft()\n",
    "        # Grab all the adjacent nodes according to our dictionary\n",
    "        adj_nodes = graph[node]\n",
    "        remaining_elements = set(adj_nodes).difference(visited_vertices)\n",
    "        if len(remaining_elements) > 0:\n",
    "            for elem in sorted(remaining_elements):\n",
    "                visited_vertices.append(elem)\n",
    "                graph_queue.append(elem)\n",
    "                \n",
    "    return visited_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'D', 'G', 'E', 'F', 'C', 'H']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breadth_first_search(graph, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the worst-case scenario, each vertex or node and the edge will be traversed, thus the time complexity of the BFS algorithm is $\\mathcal{O}(|V| + |E|)$, where $|V|$ is the number of vertices and $|E|$ is the number of edges.\n",
    "### Depth-first search\n",
    "As the name suggests, the DFS algorithm traverses the depth of any particular path in the graph before traversing the breadth. As such, child nodes are visited first before sibling nodes. The `stack` data structure is used to implement the DFS algorithm.\n",
    "\n",
    "See pages 214-216 for visual example of DFS algorithm. We implement the DFS algorithm on the graph corresponding to the adjacency list of the graph from those pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_graph = dict()\n",
    "dfs_graph['A'] = ['B', 'S']\n",
    "dfs_graph['B'] = ['A']\n",
    "dfs_graph['S'] = ['A', 'C', 'G']\n",
    "dfs_graph['C'] = ['S', 'D', 'E', 'F']\n",
    "dfs_graph['D'] = ['C']\n",
    "dfs_graph['E'] = ['C', 'H']\n",
    "dfs_graph['F'] = ['C', 'G']\n",
    "dfs_graph['G'] = ['S', 'F', 'H']\n",
    "dfs_graph['H'] = ['E', 'G']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the DFS algorithm begins by creating a list to store the visited nodes. The `graph_stack` stack variable is used to aid the traversal process. We are using a regular Python list as a stack. The starting node, called `root`, is passed with the graph;s adjacency matrix, graph. `root` is pushed onto the stack. `node = root` holds the first node in the stack:\n",
    "```python\n",
    "def depth_first_search(graph, root):\n",
    "    visited_vertices = list()\n",
    "    graph_stack = list()\n",
    "    # Append the root to the graph_stack\n",
    "    graph_stack.append(root)\n",
    "    node = root\n",
    "```\n",
    "The body of the `while` loop will be executed, provided the stack is not empty. If `node` is not in the list of visited nodes, we add it. All adjacent nodes to `node` are collected by `adj_nodes = graph[node]`. If all the adjacent nodes have been visited, we pop that node from the stack and set `node` to `graph_stack[-1].graph_stack[-1]` is the top node on the stack. The `continue` statement jumps back to the beginning of the `while` loop's test condition.\n",
    "```python\n",
    "    while len(graph_stack) > 0:\n",
    "        if node not in visited_vertices:\n",
    "            visited_vertices.append(node)\n",
    "        adj_nodes = graph[node]\n",
    "        if set(adj_nodes).issubset(set(visited_vertices)):\n",
    "            graph_stack.pop()\n",
    "            if len(graph_stack) > 0:\n",
    "                node = graph_stack[-1]\n",
    "            continue\n",
    "            else:\n",
    "                remaining_elements = set(adj_nodes).difference(set(visited_vertices))\n",
    "            first_adj_node = sorted(remaining_elements)[0]\n",
    "            graph_stack.append(first_adj_node)\n",
    "            node = first_adj_node\n",
    "        return visited_vertices\n",
    "```\n",
    "If, on the other hand, not all the adjacent nodes have been visited, then the nodes that are yet to be visited are obtained by finding the difference between the `adj_nodes` and `visited_vertices` with the `remaining_elements = set(adj_nodes).difference(set(visited_vertices))` statement. The first item within `sorted(remaining_elements)` is assigned to `first_adj_node`, and pushed onto the stack. We then point the top of the stack to this node. When the `while` loop exists, we will return `visited_vertices`.\n",
    "\n",
    "We will now explain the working of the source code by relating it to the previous example. The `A` node is chosen as our starting node. `A` is pushed onto the stack and added to the `visited_vertices` list. In doing so, we mark it as having been visited. The `graph_stack` stack is implemented with a simple Python list. Our stack now has A as its only element. We examine the A node;s adjacent nodes, B and S. To test whether all the adjacent nodes of A have been visited, we usethe `if` statement:\n",
    "```python\n",
    "        if set(adj_nodes).issubset(set(visited_vertices)):\n",
    "            graph_stack.pop()\n",
    "            if len(graph_stack) > 0:\n",
    "                node = graph_stack[-1]\n",
    "            continue\n",
    "```\n",
    "If all the nodes have been visited, we pop the top of the stack. If the `graph_stack` stack is not empty, we assign the node on top of the stack to `node` and start the beginning of another execution of the body of the `while` loop. The `set(adj_nodes).issubset(set(visited_vertices))` statement will evaluate to `True` if all the nodes in `adj_nodes` are a subset of `visited_vertices`. If the `if` statement fails, it means that some nodes remain to be visited. We obtain that list of nodes with `remaining_elements = set(adj_nodes).difference(set(visited_vertices))`. Referring to the diagram on pages 214-216, the B and S nodes will be stored in `remaining_elements`. We will access the list in alphabetical order as follows:\n",
    "```python\n",
    "    first_adj_node = sorted(remaining_elements)[0]\n",
    "    graph_stack.append(first_adj_node)\n",
    "    node = first_adj_node\n",
    "```\n",
    "We sort `remaining_elements` and return the first node to `first_adj_node`. This will return B. We push the B node onto the stack by appending it to the `graph_stack`. We prepare the B node for access by assigning it to `node`.\n",
    "\n",
    "On the next iteration of the `while` loop, we add the B node to the list of `visited_nodes`. We discovered that the only adjacent node to B, which is A, has already been visited. Because all the adjacent nodes of B have been visited, we pop it off the stack, leaving A as the only element on the stack. We return to A and examine whether all of its adjacent nodes have been visited. The A node has S as the only unvisited node. We push S to the stack and begin the whole process again.\n",
    "\n",
    "DFS find applications in solving maze problems, finding connected components, and finding the bridges of a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(graph, root): \n",
    "        visited_vertices = list() \n",
    "        graph_stack = list() \n",
    "        graph_stack.append(root) \n",
    "        node = root \n",
    "        while len(graph_stack) > 0: \n",
    "            if node not in visited_vertices: \n",
    "                visited_vertices.append(node) \n",
    "            adj_nodes = graph[node] \n",
    "            if set(adj_nodes).issubset(set(visited_vertices)): \n",
    "                graph_stack.pop() \n",
    "                if len(graph_stack) > 0: \n",
    "\t                node = graph_stack[-1] \n",
    "                continue \n",
    "            else: \n",
    "                remaining_elements = set(adj_nodes).difference(set(visited_vertices)) \n",
    "            first_adj_node = sorted(remaining_elements)[0] \n",
    "            graph_stack.append(first_adj_node) \n",
    "            node = first_adj_node \n",
    "        return visited_vertices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'S', 'C', 'D', 'E', 'H', 'G', 'F']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_first_search(dfs_graph, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful graph methods\n",
    "It is very often that we need to use graphs for finding a path between two nodes. Sometimes, it is necessary to find all the paths between nodes, and in some situations, we might need to find the shortest path between nodes. For example, in routing applications, we generally use various algorithms to determine the shortest path from the source node to the destination node. For an unweighted graph, we would simply determine the path with the lowest number of edges between them. If a weighted graph is given, we have to calculate the total weight of passing through a set of edges. Thus, in a different siutation, we may have to find the longest or shortest path using different algorithms.\n",
    "### Priority queues and heaps\n",
    "A priority queue is a data structure which is similar to the queue and stack data structures that stores data along with the priority associated with it. In the priority queue, the item with the highest priority is served first. Priority quques are often implemented using a heap, since it is very efficient for this purpose; however, it can be implemented using other data structures. It is a modified queue that returns the items in the order of highest priority, whereas the queue returns the items in the order that the items were added. The priority queue is used in many applications, such as CPU scheduling.\n",
    "\n",
    "Refer to first paragraph of page 220 if you want to know the difference between a regular and a priority queue.\n",
    "\n",
    "A heap is a data structure that satisfies a heap property. A heap property states that these must be a certain relationship between a parent node and its child nodes. This property must apply throughout the entire heap.\n",
    "\n",
    "In a min(imum) heap, the relationship between the parent and children is that the value at the parent must always be less than or equal to its children. As a consequence of this, the lowest element in the heap must be the root node.\n",
    "\n",
    "In a max(imum) heap, on the other hand, the parent is greater than or equal to its child or its children. It follows from this that the largest value makes up the root node.\n",
    "\n",
    "Heaps are binary trees, and although we are going to use a binary tree, we will actually use a list to represent it. The heap stores a complete binary tree. A complete binary tree is one in which each row must be fully filled before starting to fill the next row.\n",
    "\n",
    "To make the math with indices easier, we are going to leave the first item in the list empty. After that, we place the tree nodes into the list, from top to bottom and left to right. The left child will always have an index in the form $2n, n \\in \\mathbb{N}$, and the right child will always have an index in the form $2n + 1, n \\in \\mathbb{N}$.\n",
    "\n",
    "Here is the implmentation of the min heap, and the max heap will be shown afterwwards. We start with the heap class:\n",
    "```python\n",
    "class Heap:\n",
    "    def __init__(self):\n",
    "        self.heap = [0]\n",
    "        self.size = 0\n",
    "```\n",
    "We initialize our heap list with a zero to represent the dummy first element. We also create a variable to hold the size of the heap.\n",
    "### Insert operation\n",
    "Inserting an item to the min heap works in two steps. First, we add the new element to the end of the list, and we increment the size of the heap by one. Secondly, after each insertion operation, we need to arrange the new element up in the heap tree, to organize all the nodes in such a way that it satisfies the heap property. This is to remind us that the lowest element in the min-heap needs to be the root element.\n",
    "\n",
    "We first create a helper method, called `arrange` that takes care of arranging all the nodes after insertion. Let's consider an example of adding an element in the min heap (see pages 222 & 223).\n",
    "```python\n",
    "def arrange(self, k):\n",
    "    \"\"\"\n",
    "    Loop until we have reached the root node, so that we can keep arranging the element up as \n",
    "    high as it needs. Since we are using integer division, as soon as we get below 2, the loop\n",
    "    will break out.\n",
    "    \"\"\"\n",
    "    while k // 2 > 0:\n",
    "        if self.heap[k] < self.heap[k // 2]:\n",
    "            self.heap[k], self.heap[k // 2] = self.heap[k // 2], self.[k]\n",
    "            # Move up the tree\n",
    "        k //= 2\n",
    "```\n",
    "We just need to call this from our insert method:\n",
    "```python\n",
    "def insert(self, item):\n",
    "    self.heap.append(item)\n",
    "    self.size += 1\n",
    "    self.arrange(self.size)\n",
    "```\n",
    "### Pop operation\n",
    "The `pop` operation removes an element from the heap. The reason for removing an element from the min-heap is, first, to find out the index of the item to be deleted, and then oranize the heap so that it satisfies the heap property. However, it is more common to pop off the minimum value from the min-heap, and as per the property of the min-heap, we can get the minimum value by its root value. Therefore, to obtain and remove the minimum value from the min-heap, we remove the root node and re-organize all the nodes of the heap. We also decrement the size of the heap by one.\n",
    "\n",
    "However, once the root has been popped off, we need a new root node. For this, we just take the last item from the list and make it the new root. That is, we move it to the beginning of the list. However, the selected last node might not be the lowest element of the heap, so we have to reorganize the nodes of the heap. To structure all the nodes accoring to the min-heap property, we follow a strategy that is opposite to the `arrange()` method that we used while inserting an element into the heap. We make the last node a new node and then we let it move down as required.\n",
    "\n",
    "See example on pages 224-226.\n",
    "\n",
    "Here is the implementation of the `sink()` method. Before we implement the `sink()` method, we need to note how we determine which of the children to compare against the parent node.\n",
    "```python\n",
    "def minindex(self, k):\n",
    "    # Case where we get beyond the end of the list\n",
    "    if 2 * k + 1 > self.size:\n",
    "        return 2 * k\n",
    "    # Otherwise we return the lesser of the two children\n",
    "    elif self.heap[2*k] < self.heap[2*k + 1]:\n",
    "        return 2 * k\n",
    "    else:\n",
    "        return 2 * k + 1\n",
    "```\n",
    "Now we can create the `sink()` function. As we did before, we are going to loop so that we can sink our element down as far as is needed:\n",
    "```python\n",
    "def sink(self, k):\n",
    "    while 2*k <= self.size:\n",
    "        # Need to know which of the left or right children to compare against\n",
    "        # Use the minindex method\n",
    "        mi = self.minindex(k)\n",
    "        # Compare parent and child to see whether we need to make the swap\n",
    "        if self.heap[k] > self.heap[mi]:\n",
    "            self.heap[k], self.heap[mi] = self.heap[mi], self.heap[k]\n",
    "        # Make sure to move down the tree\n",
    "        k = mi\n",
    "```\n",
    "The only thing remaining now is to implement the main `pop()` method itself. This is very straightforward, as the grunt work is performed by the `sink()` method:\n",
    "```python\n",
    "def pop(self):\n",
    "    item = self.heap[1]\n",
    "    self.heap[1] = self.heap[self.size]\n",
    "    self.size -= 1\n",
    "    self.heap.pop()\n",
    "    self.sink(1)\n",
    "    return item\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heap:\n",
    "    def __init__(self):\n",
    "        self.heap = [0]\n",
    "        self.size = 0\n",
    "\n",
    "    def arrange(self, k):\n",
    "        while k // 2 > 0:\n",
    "            if self.heap[k] < self.heap[k//2]:\n",
    "                self.heap[k], self.heap[k//2] = self.heap[k//2], self.heap[k]\n",
    "            k //= 2\n",
    "\n",
    "    def insert(self, item):\n",
    "        self.heap.append(item)\n",
    "        self.size += 1\n",
    "        self.arrange(self.size)\n",
    "    \n",
    "    def sink(self, k):\n",
    "        while k * 2 <= self.size:\n",
    "            mc = self.minchild(k)\n",
    "            if self.heap[k] > self.heap[mc]:\n",
    "                self.heap[k], self.heap[mc] = self.heap[mc], self.heap[k]\n",
    "            k = mc\n",
    "\n",
    "    def minchild(self, k):\n",
    "        if k * 2 + 1 > self.size:\n",
    "            return k * 2\n",
    "        elif self.heap[k*2] < self.heap[k*2+1]:\n",
    "            return k * 2\n",
    "        else:\n",
    "            return k * 2 + 1\n",
    "\n",
    "    def pop(self):\n",
    "        item = self.heap[1]\n",
    "        self.heap[1] = self.heap[self.size]\n",
    "        self.size -= 1\n",
    "        self.heap.pop()\n",
    "        self.sink(1)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 5, 3, 6, 10, 7, 8, 4, 9]\n",
      "1\n",
      "[0, 2, 3, 5, 4, 6, 10, 7, 8, 9]\n",
      "2\n",
      "[0, 3, 4, 5, 8, 6, 10, 7, 9]\n",
      "3\n",
      "[0, 4, 6, 5, 8, 9, 10, 7]\n",
      "4\n",
      "[0, 5, 6, 7, 8, 9, 10]\n",
      "5\n",
      "[0, 6, 8, 7, 10, 9]\n",
      "6\n",
      "[0, 7, 8, 9, 10]\n",
      "7\n",
      "[0, 8, 10, 9]\n",
      "8\n",
      "[0, 9, 10]\n",
      "9\n",
      "[0, 10]\n",
      "10\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "h = Heap()\n",
    "for i in (4, 8, 7, 2, 9, 10, 5, 1, 3, 6):\n",
    "    h.insert(i)\n",
    "\n",
    "print(h.heap)\n",
    "\n",
    "for i in range(10):\n",
    "    n = h.pop()\n",
    "    print(n)\n",
    "    print(h.heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection algorithms\n",
    "Selection algorithms seek to answer the problem of finding the i<sup>th</sup>-smallest item in the list. When a list is in ascending order, the first element will be the smallest in the list. The second element in the list will be the second smallest item in the list. The last element in the list will be the least-smallest (largest) element in the list.\n",
    "\n",
    "In creating the heap data structure, we have come to understand that a call to the `pop` method will return the smallest element in the min-heap. The first element to pop off a min heap is the smallest element in the list. However, we will study more appraoches to find the i<sup>th</sup>-smallest element in a list. Selection algorithms have applications in filtering out noisy data, finding the median, smallest, and largest elements in a list, and even can be applied in computer chess programs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bita77d8b3ebc6c42fe84848c25c36134b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
